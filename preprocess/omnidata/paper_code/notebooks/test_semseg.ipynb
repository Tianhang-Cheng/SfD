{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-settle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange\n",
    "\n",
    "from models.multi_task_model import MultiTaskModel\n",
    "from data.taskonomy_replica_gso_dataset import TaskonomyReplicaGsoDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-racing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replica baseline\n",
    "# pretrained_weights_path = '/scratch/ainaz/omnidata2/experiments/semseg/checkpoints/omnidata/3mevrwvo/epoch=51.ckpt'\n",
    "\n",
    "# replica semseg + normal (GT)\n",
    "# pretrained_weights_path = '/scratch/ainaz/omnidata2/experiments/semseg/checkpoints/omnidata/2vts59o9/epoch=52.ckpt'\n",
    "\n",
    "# replica semseg + normal + edge3d (GT)\n",
    "pretrained_weights_path = '/scratch/ainaz/omnidata2/experiments/semseg/checkpoints/omnidata/1w8z04sn/epoch=52.ckpt'\n",
    "\n",
    "# replica semseg + normal + edge3d + edge2d + keypoints3d + depth (GT) \n",
    "# pretrained_weights_path = '/scratch/ainaz/omnidata2/experiments/semseg/checkpoints/omnidata/4sk98iky/epoch=51.ckpt'\n",
    "\n",
    "# replica semseg + normal (PADNET)\n",
    "# pretrained_weights_path = '/scratch/ainaz/omnidata2/experiments/multitask/checkpoints/omnidata/1ypt36cz/last.ckpt'\n",
    "\n",
    "# replica semseg + normal + edge3d (PADNET)\n",
    "# pretrained_weights_path = '/scratch/ainaz/omnidata2/experiments/multitask/checkpoints/omnidata/29sqmzk2/last.ckpt'\n",
    "\n",
    "# replica semseg + normal + edge3d + edge2d + keypoints3d + depth (PADNET)\n",
    "# pretrained_weights_path = '/scratch/ainaz/omnidata2/experiments/multitask/checkpoints/omnidata/2rg5cep8/last.ckpt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-academy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "tasks = ['rgb', 'segment_semantic', 'normal', 'edge_occlusion', 'mask_valid']\n",
    "# tasks = ['rgb', 'normal', 'segment_semantic', 'edge_occlusion', 'edge_texture', 'keypoints3d', 'depth_zbuffer', 'mask_valid']\n",
    "taskonomy_variant = 'tiny'\n",
    "batch_size = 16\n",
    "image_size = 256\n",
    "normalize_rgb = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-bidding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiTaskModel(\n",
       "  (backbone): HighResolutionNet(\n",
       "    (conv1): Conv2d(7, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (transition1): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(256, 36, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(36, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (stage2): Sequential(\n",
       "      (0): HighResolutionModule(\n",
       "        (branches): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "              (conv2): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "              (conv2): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "              (conv2): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(36, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "              (conv2): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(36, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (fuse_layers): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): None\n",
       "            (1): Sequential(\n",
       "              (0): Conv2d(36, 18, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Conv2d(18, 36, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(36, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): None\n",
       "          )\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (transition2): ModuleList(\n",
       "      (0): None\n",
       "      (1): None\n",
       "      (2): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(36, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(72, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (stage3): Sequential(\n",
       "      (0): HighResolutionModule(\n",
       "        (branches): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "              (conv2): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "              (conv2): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "              (conv2): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(36, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "              (conv2): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(36, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "              (conv2): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(72, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "              (conv2): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(72, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (fuse_layers): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): None\n",
       "            (1): Sequential(\n",
       "              (0): Conv2d(36, 18, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (2): Sequential(\n",
       "              (0): Conv2d(72, 18, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Conv2d(18, 36, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(36, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): None\n",
       "            (2): Sequential(\n",
       "              (0): Conv2d(72, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(36, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (2): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Conv2d(18, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "                (2): ReLU()\n",
       "              )\n",
       "              (1): Sequential(\n",
       "                (0): Conv2d(18, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(72, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Conv2d(36, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(72, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (2): None\n",
       "          )\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): HighResolutionModule(\n",
       "        (branches): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "              (conv2): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "              (conv2): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "              (conv2): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(36, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "              (conv2): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(36, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "              (conv2): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(72, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "              (conv2): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(72, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (fuse_layers): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): None\n",
       "            (1): Sequential(\n",
       "              (0): Conv2d(36, 18, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (2): Sequential(\n",
       "              (0): Conv2d(72, 18, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Conv2d(18, 36, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(36, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): None\n",
       "            (2): Sequential(\n",
       "              (0): Conv2d(72, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(36, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (2): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Conv2d(18, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "                (2): ReLU()\n",
       "              )\n",
       "              (1): Sequential(\n",
       "                (0): Conv2d(18, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(72, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Conv2d(36, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(72, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (2): None\n",
       "          )\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (2): HighResolutionModule(\n",
       "        (branches): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "              (conv2): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "              (conv2): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "              (conv2): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(36, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "              (conv2): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(36, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "              (conv2): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(72, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "              (conv2): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(72, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (fuse_layers): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): None\n",
       "            (1): Sequential(\n",
       "              (0): Conv2d(36, 18, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (2): Sequential(\n",
       "              (0): Conv2d(72, 18, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Conv2d(18, 36, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(36, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): None\n",
       "            (2): Sequential(\n",
       "              (0): Conv2d(72, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(36, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (2): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Conv2d(18, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "                (2): ReLU()\n",
       "              )\n",
       "              (1): Sequential(\n",
       "                (0): Conv2d(18, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(72, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Conv2d(36, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(72, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (2): None\n",
       "          )\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (transition3): ModuleList(\n",
       "      (0): None\n",
       "      (1): None\n",
       "      (2): None\n",
       "      (3): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(72, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (stage4): Sequential(\n",
       "      (0): HighResolutionModule(\n",
       "        (branches): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "              (conv2): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "              (conv2): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "              (conv2): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(36, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "              (conv2): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(36, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "              (conv2): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(72, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "              (conv2): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(72, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (3): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "              (conv2): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "              (conv2): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (fuse_layers): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): None\n",
       "            (1): Sequential(\n",
       "              (0): Conv2d(36, 18, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (2): Sequential(\n",
       "              (0): Conv2d(72, 18, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (3): Sequential(\n",
       "              (0): Conv2d(144, 18, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Conv2d(18, 36, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(36, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): None\n",
       "            (2): Sequential(\n",
       "              (0): Conv2d(72, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(36, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (3): Sequential(\n",
       "              (0): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(36, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (2): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Conv2d(18, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "                (2): ReLU()\n",
       "              )\n",
       "              (1): Sequential(\n",
       "                (0): Conv2d(18, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(72, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Conv2d(36, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(72, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (2): None\n",
       "            (3): Sequential(\n",
       "              (0): Conv2d(144, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(72, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (3): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Conv2d(18, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "                (2): ReLU()\n",
       "              )\n",
       "              (1): Sequential(\n",
       "                (0): Conv2d(18, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "                (2): ReLU()\n",
       "              )\n",
       "              (2): Sequential(\n",
       "                (0): Conv2d(18, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(144, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Conv2d(36, 36, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(36, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "                (2): ReLU()\n",
       "              )\n",
       "              (1): Sequential(\n",
       "                (0): Conv2d(36, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(144, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Conv2d(72, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(144, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (3): None\n",
       "          )\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): HighResolutionModule(\n",
       "        (branches): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "              (conv2): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "              (conv2): Conv2d(18, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "              (conv2): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(36, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "              (conv2): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(36, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "              (conv2): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(72, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "              (conv2): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(72, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (3): Sequential(\n",
       "            (0): BasicBlock(\n",
       "              (conv1): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "              (conv2): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (1): BasicBlock(\n",
       "              (conv1): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "              (conv2): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (fuse_layers): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): None\n",
       "            (1): Sequential(\n",
       "              (0): Conv2d(36, 18, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (2): Sequential(\n",
       "              (0): Conv2d(72, 18, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (3): Sequential(\n",
       "              (0): Conv2d(144, 18, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Conv2d(18, 36, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(36, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): None\n",
       "            (2): Sequential(\n",
       "              (0): Conv2d(72, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(36, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (3): Sequential(\n",
       "              (0): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(36, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (2): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Conv2d(18, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "                (2): ReLU()\n",
       "              )\n",
       "              (1): Sequential(\n",
       "                (0): Conv2d(18, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(72, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Conv2d(36, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(72, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (2): None\n",
       "            (3): Sequential(\n",
       "              (0): Conv2d(144, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(72, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (3): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Conv2d(18, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "                (2): ReLU()\n",
       "              )\n",
       "              (1): Sequential(\n",
       "                (0): Conv2d(18, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(18, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "                (2): ReLU()\n",
       "              )\n",
       "              (2): Sequential(\n",
       "                (0): Conv2d(18, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(144, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Conv2d(36, 36, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(36, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "                (2): ReLU()\n",
       "              )\n",
       "              (1): Sequential(\n",
       "                (0): Conv2d(36, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(144, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Sequential(\n",
       "              (0): Sequential(\n",
       "                (0): Conv2d(72, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(144, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (3): None\n",
       "          )\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoders): ModuleDict(\n",
       "    (segment_semantic): HighResolutionHead(\n",
       "      (last_layer): Sequential(\n",
       "        (0): Conv2d(270, 270, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(270, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(270, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = MultiTaskModel(tasks=['segment_semantic'], n_channels=7, \n",
    "                       backbone='hrnet_w18', head='hrnet', pretrained=False, dilated=False)\n",
    "\n",
    "checkpoint = torch.load(pretrained_weights_path, map_location='cuda:0')\n",
    "if 'state_dict' in checkpoint:\n",
    "    state_dict = {}\n",
    "    for k, v in checkpoint['state_dict'].items():\n",
    "        state_dict[k.replace('model.', '')] = v\n",
    "else:\n",
    "      state_dict = checkpoint\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-train",
   "metadata": {},
   "source": [
    "# Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-liechtenstein",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!  ./tmp/taskonomy_rgb-normal-segment_semantic-keypoints2d-keypoints3d-depth_zbuffer-edge_texture-edge_occlusion-mask_valid_tiny-test.pkl\n",
      "!! here\n",
      "Loaded taskonomy with 54514 images from tmp.\n",
      "!!!!!!!!!!!! rgb :  54514\n",
      "!!!!!!!!!!!! semantic segmentation :  54514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded 53386 images in 1.06 seconds\n",
      "\t (5 buildings) (8759 points) (53386 images) for domains ['rgb', 'segment_semantic', 'normal', 'edge_occlusion', 'mask_valid']\n"
     ]
    }
   ],
   "source": [
    "opt_test_taskonomy = TaskonomyReplicaGsoDataset.Options(\n",
    "    split='test',\n",
    "    taskonomy_variant=taskonomy_variant,\n",
    "    tasks=tasks,\n",
    "    datasets=['taskonomy'],\n",
    "    transform='DEFAULT',\n",
    "    image_size=image_size,\n",
    "    normalize_rgb=normalize_rgb,\n",
    "    randomize_views=False\n",
    ")\n",
    "\n",
    "testset_taskonomy = TaskonomyReplicaGsoDataset(options=opt_test_taskonomy)\n",
    "\n",
    "# opt_test_replica = TaskonomyReplicaGsoDataset.Options(\n",
    "#     split='test',\n",
    "#     taskonomy_variant=taskonomy_variant,\n",
    "#     tasks=tasks,\n",
    "#     datasets=['replica'],\n",
    "#     transform='DEFAULT',\n",
    "#     image_size=image_size,\n",
    "#     normalize_rgb=normalize_rgb,\n",
    "#     randomize_views=False\n",
    "# )\n",
    "\n",
    "# testset_replica = TaskonomyReplicaGsoDataset(options=opt_test_replica)\n",
    "\n",
    "# opt_test_hypersim = TaskonomyReplicaGsoDataset.Options(\n",
    "#     split='test',\n",
    "#     taskonomy_variant=taskonomy_variant,\n",
    "#     tasks=tasks,\n",
    "#     datasets=['hypersim'],\n",
    "#     transform='DEFAULT',\n",
    "#     image_size=image_size,\n",
    "#     normalize_rgb=normalize_rgb,\n",
    "#     randomize_views=False\n",
    "# )\n",
    "\n",
    "# testset_hypersim = TaskonomyReplicaGsoDataset(options=opt_test_hypersim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-interest",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader_taskonomy = DataLoader(\n",
    "    testset_taskonomy, batch_size=batch_size, shuffle=False, num_workers=64, pin_memory=False\n",
    ")\n",
    "# test_dataloader_replica = DataLoader(\n",
    "#     testset_replica, batch_size=batch_size, shuffle=False, num_workers=64, pin_memory=False\n",
    "# )\n",
    "# test_dataloader_hypersim = DataLoader(\n",
    "#     testset_hypersim, batch_size=batch_size, shuffle=False, num_workers=1, pin_memory=False\n",
    "# )\n",
    "# test_dataloader_combined = DataLoader(\n",
    "#     ConcatDataset([testset_taskonomy, testset_replica, testset_hypersim]), \n",
    "#     batch_size=batch_size, shuffle=False, num_workers=64, pin_memory=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-supplement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3337\n"
     ]
    }
   ],
   "source": [
    "print(len(test_dataloader_taskonomy))\n",
    "# print(len(test_dataloader_replica))\n",
    "# print(len(test_dataloader_hypersim))\n",
    "# print(len(test_dataloader_combined))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-budget",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-amount",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_valid_mask(mask_float, max_pool_size=4, return_small_mask=False):\n",
    "    '''\n",
    "        Creates a mask indicating the valid parts of the image(s).\n",
    "        Enlargens masked area using a max pooling operation.\n",
    "\n",
    "        Args:\n",
    "            mask_float: A mask as loaded from the Taskonomy loader.\n",
    "            max_pool_size: Parameter to choose how much to enlarge masked area.\n",
    "            return_small_mask: Set to true to return mask for aggregated image\n",
    "    '''\n",
    "    if len(mask_float.shape) == 3:\n",
    "        mask_float = mask_float.unsqueeze(axis=0)\n",
    "    reshape_temp = len(mask_float.shape) == 5\n",
    "    if reshape_temp:\n",
    "        mask_float = rearrange(mask_float, 'b p c h w -> (b p) c h w')\n",
    "    mask_float = 1 - mask_float\n",
    "    mask_float = F.max_pool2d(mask_float, kernel_size=max_pool_size)\n",
    "    mask_float = F.interpolate(mask_float, (image_size, image_size), mode='nearest')\n",
    "    mask_valid = mask_float == 0\n",
    "    if reshape_temp:\n",
    "        mask_valid = rearrange(mask_valid, '(b p) c h w -> b p c h w', p=1)\n",
    "\n",
    "    return mask_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-alcohol",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rbachman/miniconda/envs/py38/lib/python3.8/site-packages/torchvision/transforms/functional.py:70: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629411241/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
      "/home/rbachman/miniconda/envs/py38/lib/python3.8/site-packages/torchvision/transforms/functional.py:70: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629411241/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
      "/home/rbachman/miniconda/envs/py38/lib/python3.8/site-packages/torchvision/transforms/functional.py:70: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629411241/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
      "/home/rbachman/miniconda/envs/py38/lib/python3.8/site-packages/torchvision/transforms/functional.py:70: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629411241/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
      "/home/rbachman/miniconda/envs/py38/lib/python3.8/site-packages/torchvision/transforms/functional.py:70: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629411241/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
      "/home/rbachman/miniconda/envs/py38/lib/python3.8/site-packages/torchvision/transforms/functional.py:70: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629411241/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
      "/home/rbachman/miniconda/envs/py38/lib/python3.8/site-packages/torchvision/transforms/functional.py:70: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629411241/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
      "/home/rbachman/miniconda/envs/py38/lib/python3.8/site-packages/torchvision/transforms/functional.py:70: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629411241/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
      "/home/rbachman/miniconda/envs/py38/lib/python3.8/site-packages/torchvision/transforms/functional.py:70: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629411241/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
      "/home/rbachman/miniconda/envs/py38/lib/python3.8/site-packages/torchvision/transforms/functional.py:70: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629411241/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
      "/home/rbachman/miniconda/envs/py38/lib/python3.8/site-packages/torchvision/transforms/functional.py:70: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629411241/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
      "/home/rbachman/miniconda/envs/py38/lib/python3.8/site-packages/torchvision/transforms/functional.py:70: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629411241/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
      "/home/rbachman/miniconda/envs/py38/lib/python3.8/site-packages/torchvision/transforms/functional.py:70: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629411241/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rbachman/miniconda/envs/py38/lib/python3.8/site-packages/torchvision/transforms/functional.py:70: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629411241/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
      "/home/rbachman/miniconda/envs/py38/lib/python3.8/site-packages/torchvision/transforms/functional.py:70: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629411241/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
      "/home/rbachman/miniconda/envs/py38/lib/python3.8/site-packages/torchvision/transforms/functional.py:70: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629411241/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
      "/home/rbachman/miniconda/envs/py38/lib/python3.8/site-packages/torchvision/transforms/functional.py:70: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629411241/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
      "/home/rbachman/miniconda/envs/py38/lib/python3.8/site-packages/torchvision/transforms/functional.py:70: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629411241/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
      "/home/rbachman/miniconda/envs/py38/lib/python3.8/site-packages/torchvision/transforms/functional.py:70: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629411241/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
      "/home/rbachman/miniconda/envs/py38/lib/python3.8/site-packages/torchvision/transforms/functional.py:70: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629411241/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
      "/home/rbachman/miniconda/envs/py38/lib/python3.8/site-packages/torchvision/transforms/functional.py:70: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629411241/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
      "/home/rbachman/miniconda/envs/py38/lib/python3.8/site-packages/torchvision/transforms/functional.py:70: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629411241/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
      "/home/rbachman/miniconda/envs/py38/lib/python3.8/site-packages/torchvision/transforms/functional.py:70: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629411241/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
      "/home/rbachman/miniconda/envs/py38/lib/python3.8/site-packages/torchvision/transforms/functional.py:70: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629411241/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
      "/home/rbachman/miniconda/envs/py38/lib/python3.8/site-packages/torchvision/transforms/functional.py:70: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629411241/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
      "/home/rbachman/miniconda/envs/py38/lib/python3.8/site-packages/torchvision/transforms/functional.py:70: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629411241/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rbachman/miniconda/envs/py38/lib/python3.8/site-packages/torchvision/transforms/functional.py:70: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629411241/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
      "/home/rbachman/miniconda/envs/py38/lib/python3.8/site-packages/torchvision/transforms/functional.py:70: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629411241/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
      "/home/rbachman/miniconda/envs/py38/lib/python3.8/site-packages/torchvision/transforms/functional.py:70: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629411241/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
      "/home/rbachman/miniconda/envs/py38/lib/python3.8/site-packages/torchvision/transforms/functional.py:70: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629411241/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
      "/home/rbachman/miniconda/envs/py38/lib/python3.8/site-packages/torchvision/transforms/functional.py:70: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629411241/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
      "/home/rbachman/miniconda/envs/py38/lib/python3.8/site-packages/torchvision/transforms/functional.py:70: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629411241/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
      "/home/rbachman/miniconda/envs/py38/lib/python3.8/site-packages/torchvision/transforms/functional.py:70: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629411241/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
      "/home/rbachman/miniconda/envs/py38/lib/python3.8/site-packages/torchvision/transforms/functional.py:70: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629411241/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
      "/home/rbachman/miniconda/envs/py38/lib/python3.8/site-packages/torchvision/transforms/functional.py:70: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629411241/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
      "/home/rbachman/miniconda/envs/py38/lib/python3.8/site-packages/torchvision/transforms/functional.py:70: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629411241/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
      "/home/rbachman/miniconda/envs/py38/lib/python3.8/site-packages/torchvision/transforms/functional.py:70: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629411241/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
      "/home/rbachman/miniconda/envs/py38/lib/python3.8/site-packages/torchvision/transforms/functional.py:70: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629411241/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "\n",
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "all_pixels = 0\n",
    "pos_pixels = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step, batch in enumerate(test_dataloader_taskonomy):\n",
    "        print(step)\n",
    "        rgb = batch['positive']['rgb'].to(device)\n",
    "        semantic = batch['positive']['segment_semantic'].to(device)\n",
    "        normal = batch['positive']['normal'].to(device)\n",
    "#         depth = batch['positive']['depth_zbuffer'].to(device)\n",
    "        edge_occlusion = batch['positive']['edge_occlusion'].to(device)\n",
    "#         edge_texture = batch['positive']['edge_texture'].to(device)\n",
    "#         keypoints3d = batch['positive']['keypoints3d'].to(device)\n",
    "        mask_valid = make_valid_mask(batch['positive']['mask_valid']).squeeze(1).to(device)\n",
    "\n",
    "        labels_gt = semantic[:,:,:,0]\n",
    "\n",
    "        # background and undefined classes are labeled as 0\n",
    "        labels_gt[(semantic[:,:,:,0]==255) * (semantic[:,:,:,1]==255) * (semantic[:,:,:,2]==255)] = 0 # background in taskonomy\n",
    "        labels_gt[labels_gt==-1] = 0  # undefined class in hypersim\n",
    "\n",
    "        # mask out invalid parts of the mesh, background and undefined label\n",
    "        labels_gt *= mask_valid # invalid parts of the mesh also have label (0)\n",
    "        labels_gt -= 1  # the model should not predict undefined and background classes\n",
    "        \n",
    "#         combo_input = torch.cat([rgb, normal, depth, edge_texture, edge_occlusion, keypoints3d], dim=1)\n",
    "        combo_input = torch.cat([rgb, normal, edge_occlusion], dim=1)\n",
    "        labels_preds = model.forward(combo_input)['segment_semantic']\n",
    "\n",
    "        # loss\n",
    "        total_loss = criterion(labels_preds, labels_gt)\n",
    "        \n",
    "        # accuracy\n",
    "        mask_gt = labels_gt + 1\n",
    "        mask_valid = mask_gt != 0\n",
    "        if mask_valid.sum() == 0: continue\n",
    "        mask_preds = F.softmax(labels_preds, dim=1)\n",
    "        mask_preds = torch.argmax(mask_preds, dim=1) + 1 # model does not predict background/undefined\n",
    "        mask_preds *= mask_valid\n",
    "        mask_preds = mask_preds[mask_valid != 0]\n",
    "        mask_gt = mask_gt[mask_valid != 0]\n",
    "#         acc = (mask_preds == mask_gt).sum() * 1.0 / mask_gt.size(0)\n",
    "#         print(acc)\n",
    "\n",
    "        all_pixels += mask_gt.size(0)\n",
    "        pos_pixels += (mask_preds == mask_gt).sum()\n",
    "        \n",
    "        losses.append(total_loss)      \n",
    "#         accuracies.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-arcade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3337"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-improvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.tensor(accuracies).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-modern",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.1244)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(losses).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-newman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1290, device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_pixels * 1.0 / all_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-canyon",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
